{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdsdFqJkAikrXuXkxC9oaN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "557f2ccf38e14610b0d3574e873aa747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce30737bfc534be390c5d80551c139c6",
              "IPY_MODEL_012b1e7bfc2d49d78527cdc7b01832e7",
              "IPY_MODEL_980ca354248844c88f935975bca5b84d"
            ],
            "layout": "IPY_MODEL_7df7ab6379c94ece9d0482283d516d40"
          }
        },
        "ce30737bfc534be390c5d80551c139c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8a4fcc71b8a4978afc25a63f719d62f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_06c275c2446d42fb8e06a796012255e9",
            "value": "Epoch 0:   0%"
          }
        },
        "012b1e7bfc2d49d78527cdc7b01832e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e40ae20cd9d042e9ab9df6d548cae3c9",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34cf54b0fb464e208b2e793caa94b055",
            "value": 0
          }
        },
        "980ca354248844c88f935975bca5b84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b9a3abab97f4ff3ba962727ca3c7529",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e6ef02f92a50400ab52fb8d5f963de7e",
            "value": " 0/6 [00:00&lt;?, ?it/s]"
          }
        },
        "7df7ab6379c94ece9d0482283d516d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "f8a4fcc71b8a4978afc25a63f719d62f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c275c2446d42fb8e06a796012255e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e40ae20cd9d042e9ab9df6d548cae3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34cf54b0fb464e208b2e793caa94b055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b9a3abab97f4ff3ba962727ca3c7529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ef02f92a50400ab52fb8d5f963de7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wanng-ide/Fengshenbang-colab/blob/main/finetune_taiyi_stable_diffusion_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üñåÔ∏è **Finetuning Taiyi-Stable-Diffusion Colab Example**\n",
        "\n",
        "#####based on https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1\n"
      ],
      "metadata": {
        "id": "-GisYq7cG41a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing fengshen framework"
      ],
      "metadata": {
        "id": "twrdGg5zaY0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install pytorch_lightning\n",
        "!pip install transformers\n",
        "!pip install deepspeed\n",
        "!pip install diffusers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "\n",
        "!git clone https://github.com/IDEA-CCNL/Fengshenbang-LM\n",
        "\n",
        "clear_output()\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y24PHP7dG4gj",
        "outputId": "a2651340-b2c9-45a0-bfb9-3e5f8a1d61e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/Fengshenbang-LM')\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwZ2CAgkLgda",
        "outputId": "106e189e-a068-4c23-e1ce-551ff0199808"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Fengshenbang-LM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building modules"
      ],
      "metadata": {
        "id": "EMYaGij5acpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CnXybs4VFJnz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "from pytorch_lightning import (\n",
        "    LightningModule,\n",
        "    Trainer,\n",
        ")\n",
        "from pytorch_lightning.callbacks import (\n",
        "    LearningRateMonitor,\n",
        ")\n",
        "from fengshen.data.universal_datamodule import UniversalDataModule\n",
        "from fengshen.models.model_utils import (\n",
        "    add_module_args,\n",
        "    configure_optimizers,\n",
        "    get_total_steps,\n",
        ")\n",
        "from fengshen.utils.universal_checkpoint import UniversalCheckpoint\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from diffusers import AutoencoderKL, DDPMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n",
        "from torch.nn import functional as F\n",
        "from fengshen.data.taiyi_stable_diffusion_datasets.taiyi_datasets import add_data_args, load_data\n",
        "\n",
        "\n",
        "class StableDiffusion(LightningModule):\n",
        "    @staticmethod\n",
        "    def add_module_specific_args(parent_parser):\n",
        "        parser = parent_parser.add_argument_group('Taiyi Stable Diffusion Module')\n",
        "        parser.add_argument('--train_whole_model', action='store_true', default=False)\n",
        "        return parent_parser\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\n",
        "            args.model_path, subfolder=\"tokenizer\")\n",
        "        self.text_encoder = BertModel.from_pretrained(\n",
        "            args.model_path, subfolder=\"text_encoder\")  # load from taiyi_finetune-v0\n",
        "        self.vae = AutoencoderKL.from_pretrained(\n",
        "            args.model_path, subfolder=\"vae\")\n",
        "        self.unet = UNet2DConditionModel.from_pretrained(\n",
        "            args.model_path, subfolder=\"unet\")\n",
        "\n",
        "        self.noise_scheduler = DDPMScheduler(\n",
        "            beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000\n",
        "        )\n",
        "        self.save_hyperparameters(args)\n",
        "\n",
        "    def setup(self, stage) -> None:\n",
        "        if stage == 'fit':\n",
        "            self.total_steps = get_total_steps(self.trainer, self.hparams)\n",
        "            print('Total steps: {}' .format(self.total_steps))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        model_params = [{'params': self.text_encoder.parameters()}]\n",
        "        if self.hparams.train_whole_model:\n",
        "            model_params.append({'params': self.unet.parameters()})\n",
        "        return configure_optimizers(self, model_params=model_params)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        self.text_encoder.train()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            latents = self.vae.encode(batch[\"pixel_values\"]).latent_dist.sample()\n",
        "            latents = latents * 0.18215\n",
        "\n",
        "        # Sample noise that we'll add to the latents\n",
        "        noise = torch.randn(latents.shape).to(latents.device)\n",
        "        noise = noise.to(dtype=self.unet.dtype)\n",
        "        bsz = latents.shape[0]\n",
        "        # Sample a random timestep for each image\n",
        "        timesteps = torch.randint(\n",
        "            0, self.noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n",
        "        timesteps = timesteps.long()\n",
        "        # Add noise to the latents according to the noise magnitude at each timestep\n",
        "        # (this is the forward diffusion process)\n",
        "\n",
        "        noisy_latents = self.noise_scheduler.add_noise(latents, noise, timesteps)\n",
        "        noisy_latents = noisy_latents.to(dtype=self.unet.dtype)\n",
        "\n",
        "        # Get the text embedding for conditioning\n",
        "        # with torch.no_grad():\n",
        "        encoder_hidden_states = self.text_encoder(batch[\"input_ids\"])[0]\n",
        "\n",
        "        # Predict the noise residual\n",
        "        noise_pred = self.unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
        "\n",
        "        loss = F.mse_loss(noise_pred, noise, reduction=\"none\").mean([1, 2, 3]).mean()\n",
        "        self.log(\"train_loss\", loss.item(),  on_epoch=False, prog_bar=True, logger=True)\n",
        "\n",
        "        if self.trainer.global_rank == 0 and self.global_step == 100:\n",
        "            # ÊâìÂç∞ÊòæÂ≠òÂç†Áî®\n",
        "            from fengshen.utils.utils import report_memory\n",
        "            report_memory('stable diffusion')\n",
        "\n",
        "        if self.trainer.global_rank == 0:\n",
        "            if (self.global_step+1) % 5000 == 0:\n",
        "                print('saving model...')\n",
        "                pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "                    args.model_path, text_encoder=self.text_encoder, tokenizer=self.tokenizer,\n",
        "                )\n",
        "                self.trainer.current_epoch\n",
        "                pipeline.save_pretrained(os.path.join(\n",
        "                    args.default_root_dir, f'hf_out_{self.trainer.current_epoch}'))\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        if self.trainer.global_rank == 0:\n",
        "            print('saving model...')\n",
        "            pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "                args.model_path, text_encoder=self.text_encoder, tokenizer=self.tokenizer,\n",
        "            )\n",
        "            self.trainer.current_epoch\n",
        "            pipeline.save_pretrained(os.path.join(\n",
        "                args.default_root_dir, f'hf_out_{self.trainer.current_epoch}'))\n",
        "\n",
        "    def on_load_checkpoint(self, checkpoint) -> None:\n",
        "        # ÂÖºÂÆπ‰ΩéÁâàÊú¨lightningÔºå‰ΩéÁâàÊú¨lightning‰ªéckptËµ∑Êù•Êó∂stepsÊï∞‰ºöË¢´ÈáçÁΩÆ‰∏∫0\n",
        "        global_step_offset = checkpoint[\"global_step\"]\n",
        "        if 'global_samples' in checkpoint:\n",
        "            self.consumed_samples = checkpoint['global_samples']\n",
        "        self.trainer.fit_loop.epoch_loop._batches_that_stepped = global_step_offset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Settings"
      ],
      "metadata": {
        "id": "jN-ATKxi1TUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "args_parser = argparse.ArgumentParser()\n",
        "args_parser = add_module_args(args_parser)\n",
        "args_parser = add_data_args(args_parser)\n",
        "args_parser = UniversalDataModule.add_data_specific_args(args_parser)\n",
        "args_parser = Trainer.add_argparse_args(args_parser)\n",
        "args_parser = StableDiffusion.add_module_specific_args(args_parser)\n",
        "args_parser = UniversalCheckpoint.add_argparse_args(args_parser)\n",
        "\n",
        "your_dataset_path = '/content/Fengshenbang-LM/fengshen/examples/finetune_taiyi_stable_diffusion/demo_dataset' #@param {type:\"string\"}\n",
        "your_model_path =  'IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1' #@param {type:\"string\"}\n",
        "train_batch_size = '1' #@param {type:\"string\"}\n",
        "\n",
        "message = [\n",
        "    '--datasets_path', your_dataset_path,\n",
        "    '--datasets_type', 'txt',\n",
        "    '--model_path', your_model_path,\n",
        "    '--train_batchsize', train_batch_size\n",
        "]\n",
        "\n",
        "args = args_parser.parse_args(args=message)\n",
        "\n",
        "pprint(vars(args), width = 230)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFnQFiQ_1S8w",
        "outputId": "44d39fdc-2135-4b7f-d44f-796ef01ea6e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accelerator': None,\n",
            " 'accumulate_grad_batches': None,\n",
            " 'adam_beta1': 0.9,\n",
            " 'adam_beta2': 0.999,\n",
            " 'adam_epsilon': 1e-08,\n",
            " 'amp_backend': 'native',\n",
            " 'amp_level': None,\n",
            " 'auto_lr_find': False,\n",
            " 'auto_scale_batch_size': False,\n",
            " 'auto_select_gpus': False,\n",
            " 'benchmark': None,\n",
            " 'center_crop': False,\n",
            " 'check_val_every_n_epoch': 1,\n",
            " 'dataloader_workers': 2,\n",
            " 'datasets_name': None,\n",
            " 'datasets_path': ['/content/Fengshenbang-LM/fengshen/examples/finetune_taiyi_stable_diffusion/demo_dataset'],\n",
            " 'datasets_type': ['txt'],\n",
            " 'default_root_dir': None,\n",
            " 'detect_anomaly': False,\n",
            " 'deterministic': None,\n",
            " 'devices': None,\n",
            " 'enable_checkpointing': True,\n",
            " 'enable_model_summary': True,\n",
            " 'enable_progress_bar': True,\n",
            " 'every_n_epochs': None,\n",
            " 'every_n_train_steps': None,\n",
            " 'fast_dev_run': False,\n",
            " 'filename': 'model-{epoch:02d}-{train_loss:.4f}',\n",
            " 'gpus': None,\n",
            " 'gradient_clip_algorithm': None,\n",
            " 'gradient_clip_val': None,\n",
            " 'inference_mode': True,\n",
            " 'ipus': None,\n",
            " 'learning_rate': 5e-05,\n",
            " 'limit_predict_batches': None,\n",
            " 'limit_test_batches': None,\n",
            " 'limit_train_batches': None,\n",
            " 'limit_val_batches': None,\n",
            " 'load_ckpt_path': './ckpt/',\n",
            " 'log_every_n_steps': 50,\n",
            " 'logger': True,\n",
            " 'lr_decay_ratio': 1.0,\n",
            " 'lr_decay_steps': 0,\n",
            " 'max_epochs': None,\n",
            " 'max_steps': -1,\n",
            " 'max_time': None,\n",
            " 'min_epochs': None,\n",
            " 'min_learning_rate': 1e-07,\n",
            " 'min_steps': None,\n",
            " 'mode': 'min',\n",
            " 'model_path': 'IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1',\n",
            " 'monitor': 'train_loss',\n",
            " 'move_metrics_to_cpu': False,\n",
            " 'multiple_trainloader_mode': 'max_size_cycle',\n",
            " 'num_nodes': 1,\n",
            " 'num_processes': None,\n",
            " 'num_sanity_val_steps': 2,\n",
            " 'num_workers': 8,\n",
            " 'overfit_batches': 0.0,\n",
            " 'plugins': None,\n",
            " 'precision': 32,\n",
            " 'profiler': None,\n",
            " 'raw_file_type': 'json',\n",
            " 'reload_dataloaders_every_n_epochs': 0,\n",
            " 'replace_sampler_ddp': True,\n",
            " 'resolution': 512,\n",
            " 'resume_from_checkpoint': None,\n",
            " 'sampler_type': 'random',\n",
            " 'save_ckpt_path': './ckpt/',\n",
            " 'save_last': False,\n",
            " 'save_on_train_epoch_end': None,\n",
            " 'save_top_k': 3,\n",
            " 'save_weights_only': False,\n",
            " 'scheduler_type': 'polynomial',\n",
            " 'strategy': None,\n",
            " 'sync_batchnorm': False,\n",
            " 'test_batchsize': 16,\n",
            " 'test_datasets_field': 'test',\n",
            " 'test_file': None,\n",
            " 'thres': 0.2,\n",
            " 'tpu_cores': None,\n",
            " 'track_grad_norm': -1,\n",
            " 'train_batchsize': 1,\n",
            " 'train_datasets_field': 'train',\n",
            " 'train_file': None,\n",
            " 'train_whole_model': False,\n",
            " 'val_batchsize': 16,\n",
            " 'val_check_interval': None,\n",
            " 'val_datasets_field': 'validation',\n",
            " 'val_file': None,\n",
            " 'warmup_ratio': 0.1,\n",
            " 'warmup_steps': 0,\n",
            " 'weight_decay': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start training"
      ],
      "metadata": {
        "id": "sgSAEhHoagek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yALlfBnj4AUF",
        "outputId": "fe328a5d-a843-471d-835f-d36b846e53a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 25 13:04:45 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = StableDiffusion(args)\n",
        "tokenizer = model.tokenizer\n",
        "datasets = load_data(args, tokenizer=tokenizer)\n",
        "\n",
        "def collate_fn(examples):\n",
        "    # print(examples)\n",
        "    input_ids = [example[\"instance_prompt_ids\"] for example in examples]\n",
        "    pixel_values = [example[\"instance_images\"] for example in examples]\n",
        "\n",
        "    pixel_values = torch.stack(pixel_values)\n",
        "    pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
        "\n",
        "    input_ids = tokenizer.pad({\"input_ids\": input_ids}, padding=True,\n",
        "                                return_tensors=\"pt\").input_ids\n",
        "    batch = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"pixel_values\": pixel_values,\n",
        "    }\n",
        "\n",
        "    return batch\n",
        "\n",
        "datamoule = UniversalDataModule(\n",
        "    tokenizer=tokenizer, collate_fn=collate_fn, args=args, datasets=datasets)\n",
        "\n",
        "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
        "checkpoint_callback = UniversalCheckpoint(args)\n",
        "\n",
        "trainer = Trainer.from_argparse_args(args,\n",
        "                                        callbacks=[\n",
        "                                            lr_monitor,\n",
        "                                            checkpoint_callback])\n",
        "\n",
        "trainer.fit(model, datamoule, ckpt_path=args.load_ckpt_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591,
          "referenced_widgets": [
            "557f2ccf38e14610b0d3574e873aa747",
            "ce30737bfc534be390c5d80551c139c6",
            "012b1e7bfc2d49d78527cdc7b01832e7",
            "980ca354248844c88f935975bca5b84d",
            "7df7ab6379c94ece9d0482283d516d40",
            "f8a4fcc71b8a4978afc25a63f719d62f",
            "06c275c2446d42fb8e06a796012255e9",
            "e40ae20cd9d042e9ab9df6d548cae3c9",
            "34cf54b0fb464e208b2e793caa94b055",
            "3b9a3abab97f4ff3ba962727ca3c7529",
            "e6ef02f92a50400ab52fb8d5f963de7e"
          ]
        },
        "id": "b4nSmmNrLVwG",
        "outputId": "5a767379-929f-4132-96a1-9694587f3d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading folder data from /content/Fengshenbang-LM/fengshen/examples/finetune_taiyi_stable_diffusion/demo_dataset/part_0.\n",
            "Done loading data. Len of images: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------warning no checkpoint found--------, remove args\n",
            "Total steps: 6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/setup.py:178: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
            "  category=PossibleUserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py:97: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "  category=PossibleUserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:106: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
            "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name         | Type                 | Params\n",
            "------------------------------------------------------\n",
            "0 | text_encoder | BertModel            | 102 M \n",
            "1 | vae          | AutoencoderKL        | 83.7 M\n",
            "2 | unet         | UNet2DConditionModel | 859 M \n",
            "------------------------------------------------------\n",
            "1.0 B     Trainable params\n",
            "0         Non-trainable params\n",
            "1.0 B     Total params\n",
            "4,181.770 Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1562: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  category=PossibleUserWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "557f2ccf38e14610b0d3574e873aa747"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}